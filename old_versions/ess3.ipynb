{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P3 - Behavioral Cloning"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "done on AMZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import csv\n",
    "import glob\n",
    "import json\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.layers import Dense, Activation, Dropout,Conv2D,Convolution2D,MaxPooling2D,Flatten,Lambda\n",
    "from keras.models import Sequential, Model\n",
    "from keras import backend as K\n",
    "from keras.regularizers import l2\n",
    "from keras import callbacks\n",
    "from keras.models import model_from_json\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(8,6))\n",
    "#plt.rcParams['figure.figsize'] = 15, 20\n",
    "\n",
    "\n",
    "print('--- done ---')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#get the recorded data\n",
    "\n",
    "!wget https://d17h27t6h515a5.cloudfront.net/topher/2016/December/584f6edd_data/data.zip \n",
    "!unzip -q data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Keras init, CPU / GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import __version__ as keras_version\n",
    "print('Keras version:', keras_version)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#only with Keras2+\n",
    "from keras import backend as K \n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/a/45905793/3563822\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA EXPLORATION\n",
    "\n",
    "- all images are stored in data/IMG/\n",
    "- `driving_log.csv` contains the paths of acquired images (for training) and the corresponding parameter values:\n",
    "    \n",
    "    *center_camera, left_camera, right_camera, steering_angle, throttle, brake, speed *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH, has_header = 'data/', True\n",
    "#DATA_PATH, has_header = 'CarNDTrackData2/', False\n",
    "\n",
    "training_dat = pd.read_csv(DATA_PATH + 'driving_log.csv', names=None)\n",
    "training_dat.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_PATH + 'driving_log.csv', 'r') as csvfile:\n",
    "    file_reader = csv.reader(csvfile, delimiter=',')\n",
    "    log = list(file_reader)\n",
    "\n",
    "log = np.array(log)\n",
    "if has_header: log = np.delete(log, (0), axis=0) #remove the header\n",
    "\n",
    "print('Dataset:\\n {} images | Number of steering data: {}'.format(3 * len(log), len(log))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: the number of images listed in 'driving_log.csv' and the ones present in 'data/IMG' are equal.\n",
    "ls_imgs = glob.glob(DATA_PATH + 'IMG/*.jpg')\n",
    "print('len(ls_imgs):', len(ls_imgs))\n",
    "assert len(ls_imgs) == len(log) * 3, 'Actual number of *jpg images does not match with the csv log file'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Visualization\n",
    "The images are RGB format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#index of columns in: center_camera, left_camera, right_camera, steering_angle, throttle, brake, speed\n",
    "CENTER_CAM, LEFT_CAM, RIGHT_CAM, STEERING_ANGLE = range(4)\n",
    "\n",
    "center_im = log[:, CENTER_CAM]\n",
    "left_im = log[:, LEFT_CAM]\n",
    "right_im = log[:, RIGHT_CAM]\n",
    "steering_rad = log[:, STEERING_ANGLE].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N_IMGS = 20 # number of images to display\n",
    "ls_imgs = np.random.choice(np.arange(len(log)), size = N_IMGS, replace=False)\n",
    "\n",
    "NR = 4 #number of rows for display\n",
    "_, ax = plt.subplots(NR, N_IMGS // NR, figsize=(20,10))\n",
    "\n",
    "print()\n",
    "for n, idx in enumerate(ls_imgs): \n",
    "    img = cv2.imread(DATA_PATH + center_im[idx])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    row, col = divmod(n, N_IMGS // NR)\n",
    "    \n",
    "    ax[row, col].imshow(img)\n",
    "    ax[row, col].text(4, -5, steering_rad[idx], fontsize=12)    \n",
    "    ax[row, col].get_xaxis().set_visible(False)\n",
    "    ax[row, col].get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steering_deg = np.rad2deg(steering_rad).astype(int)\n",
    "\n",
    "NBI = 350\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.plot(np.arange(NBI), steering_deg[100:100+NBI], 'b-')\n",
    "plt.xlabel('frame', fontsize=14)\n",
    "plt.ylabel('steering angle (deg)', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "- Steering angle of 0 has the highest occurence.\n",
    "-  There are more positive angle values than negative ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_st_angles, counts = np.unique(steering_deg, return_counts=True)\n",
    "# get unique values\n",
    "print('Number of unique angles value : {}'.format(len(unique_st_angles)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_st_angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are many zeros !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts[unique_st_angles == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(steering_deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot histogram\n",
    "_, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "ax[0].bar(unique_st_angles, counts, width=.7, color='r')\n",
    "ax[0].set_xlabel('steering angle (deg)', fontsize=14)\n",
    "ax[0].set_ylabel('count', fontsize=14)\n",
    "\n",
    "\n",
    "ax[1].bar(unique_st_angles, np.log10(counts), width=.7, color='b')\n",
    "plt.xlabel('steering angle (deg)', fontsize=14)\n",
    "plt.ylabel('log_10( count )', fontsize=14)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "cnt_neg = np.sum(steering_deg < 0)\n",
    "cnt_zero = np.sum(steering_deg == 0)\n",
    "cnt_pos = np.sum(steering_deg > 0)\n",
    "print('Count of positive angles: {} | zero angle: {} | negative angles: {}'.format(cnt_pos, cnt_zero, cnt_neg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA AUGMENTATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Horizontal flipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_IMGS = 4\n",
    "ls_imgs = np.random.choice(np.arange(len(log)), size = N_IMGS, replace=False)\n",
    "\n",
    "NR = 2 #number of rows for display : one for the normal images, one for the flipped versions\n",
    "_, ax = plt.subplots(NR, N_IMGS, figsize=(12, 3))\n",
    "col, row = 0, 0\n",
    "\n",
    "for col, idx in enumerate(ls_imgs): \n",
    "    img = cv2.imread(DATA_PATH + center_im[idx])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    ax[0, col].imshow(img)\n",
    "    ax[0, col].text(3, -5, '{:.4f}'.format(steering_rad[idx]), fontsize=10, color='black')\n",
    "    ax[0, col].get_xaxis().set_visible(False)\n",
    "    ax[0, col].get_yaxis().set_visible(False)\n",
    "\n",
    "    ax[1, col].imshow(cv2.flip(img, 1))\n",
    "    ax[1, col].text(4, -5, '{:.4f}'.format(- steering_rad[idx]), fontsize=10, color='red')\n",
    "    ax[1, col].get_xaxis().set_visible(False)\n",
    "    ax[1, col].get_yaxis().set_visible(False)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variation of brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_IMGS = 1\n",
    "ls_imgs = np.random.choice(np.arange(len(log)), size = N_IMGS, replace=False)\n",
    "\n",
    "NB_VAR = 9 #number of variations in brightness\n",
    "NR = 3 #number of rows for display\n",
    "_, ax = plt.subplots(NR, NB_VAR // NR, figsize=(12, 5))\n",
    "\n",
    "\n",
    "for idx in range(NB_VAR): \n",
    "    img_adress = DATA_PATH + center_im[idx]\n",
    "    img = cv2.imread(img_adress)\n",
    "    \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    alpha = np.random.uniform(low=.2, high=.999, size=None)\n",
    "    hsv[:,:,2] = (hsv[:,:,2] * alpha).astype('uint8')\n",
    "    rgb = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "    \n",
    "    row, col = divmod(idx, NB_VAR // NR)\n",
    "    ax[row, col].imshow(rgb)\n",
    "    \n",
    "    ax[row, col].text(3, -8, 'alpha brightness: {:.2f}'.format(alpha), fontsize=10, color='black')\n",
    "    ax[row, col].get_xaxis().set_visible(False)\n",
    "    ax[row, col].get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_IMGS = 1\n",
    "ls_imgs = np.random.choice(np.arange(len(log)), size = N_IMGS, replace=False)\n",
    "\n",
    "NB_VAR = 9 #number of variations in crop\n",
    "NR = 3 #number of rows for display\n",
    "_, ax = plt.subplots(NR, NB_VAR // NR, figsize=(12, 5))\n",
    "\n",
    "\n",
    "for idx in range(NB_VAR): \n",
    "    img_adress = DATA_PATH + center_im[idx]\n",
    "    img = cv2.imread(img_adress)\n",
    "    \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    tx_min=-20\n",
    "    tx_max=20\n",
    "    ty_lower=-2\n",
    "    ty_upper=2\n",
    "    shape = img.shape\n",
    "    col_start, col_end = abs(tx_min), shape[1]-tx_max\n",
    "    horizon, bonnet = 60, 136\n",
    "    tx = np.random.randint(tx_min, tx_max+1)\n",
    "    ty = np.random.randint(ty_lower, ty_upper+1)\n",
    "\n",
    "    #cropping\n",
    "    random_crop = img[horizon+ty:bonnet+ty, col_start+tx:col_end+tx, :]\n",
    "    \n",
    "    row, col = divmod(idx, NB_VAR // NR)\n",
    "    ax[row, col].imshow(img)\n",
    "    ax[row, col].text(3, -8, \"tx:{} |  ty:{}\".format(tx, ty), fontsize=10, color='black')\n",
    "    ax[row, col].get_xaxis().set_visible(False)\n",
    "    ax[row, col].get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Image shearing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_IMGS = 1\n",
    "ls_imgs = np.random.choice(np.arange(len(log)), size = N_IMGS, replace=False)\n",
    "\n",
    "NB_VAR = 9 #number of variations in crop\n",
    "NR = 3 #number of rows for display\n",
    "_, ax = plt.subplots(NR, NB_VAR // NR, figsize=(12, 5))\n",
    "\n",
    "\n",
    "for idx in range(NB_VAR): \n",
    "    img_adress = DATA_PATH + center_im[idx]\n",
    "    img = cv2.imread(img_adress)\n",
    "    \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    shear_range = 20\n",
    "    rows, cols, ch_ = img.shape\n",
    "    dx = np.random.randint(-shear_range, shear_range + 1)\n",
    "\n",
    "    random_point = [cols//2+ dx, rows//2]\n",
    "    pts1 = np.float32([[0,rows], [cols,rows], [cols//2,rows//2]])\n",
    "    pts2 = np.float32([[0,rows], [cols,rows], random_point])\n",
    "   \n",
    "    M = cv2.getAffineTransform(pts1,pts2)\n",
    "    img = cv2.warpAffine(img,M,(cols,rows),borderMode=1)\n",
    "    \n",
    "    delta_steering = dx/(rows/2) * 360/(2*np.pi*25.0) / 6.0\n",
    "    \n",
    "    row, col = divmod(idx, NB_VAR // NR)\n",
    "    ax[row, col].imshow(img)\n",
    "    ax[row, col].text(3, -8, \"delta_steering:{:.2f}\".format(delta_steering), fontsize=10, color='black')\n",
    "    ax[row, col].get_xaxis().set_visible(False)\n",
    "    ax[row, col].get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CROPPED_DIM = 64\n",
    "\n",
    "def random_crop(image, steering=0.0, tx_min=-20, tx_max=20, ty_min=-2, ty_max=2, rand=True):\n",
    "    \"\"\"\n",
    "    We will randomly crop subsections at the approximate center of the image and use them as our data set.\n",
    "    After that we downside the resulting image to 64x64.\n",
    "    \"\"\"\n",
    "    \n",
    "    col_start, col_end = abs(tx_min), image.shape[1] - tx_max\n",
    "    horizon, bonnet = 60, 136\n",
    "\n",
    "    if rand:\n",
    "        tx = np.random.randint(tx_min, tx_max+1)\n",
    "        ty = np.random.randint(ty_min, ty_max+1)\n",
    "    else:\n",
    "        tx, ty = 0, 0\n",
    "    \n",
    "    #cropping\n",
    "    random_crop = image[horizon+ty:bonnet+ty, col_start+tx:col_end+tx, :]\n",
    "    \n",
    "    #downsizing\n",
    "    image = cv2.resize(random_crop,(CROPPED_DIM,CROPPED_DIM), cv2.INTER_AREA)\n",
    "    \n",
    "    # the steering variable needs to be updated to counteract the shift \n",
    "    delta_steering = -tx/(tx_max - tx_min)/3.0 if tx_min != tx_max else 0 \n",
    "    steering += delta_steering\n",
    "    \n",
    "    return image, steering\n",
    "\n",
    "\n",
    "def random_shear(image, steering, shear_range=40):\n",
    "    rows, cols, ch_ = image.shape\n",
    "    \n",
    "    dx = np.random.randint(-shear_range, shear_range + 1)\n",
    "\n",
    "    random_point = [cols//2+ dx, rows//2]\n",
    "    pts1 = np.float32([[0,rows], [cols,rows], [cols//2,rows//2]])\n",
    "    pts2 = np.float32([[0,rows], [cols,rows], random_point])\n",
    "   \n",
    "    M = cv2.getAffineTransform(pts1,pts2)\n",
    "    image = cv2.warpAffine(image,M,(cols,rows),borderMode=1)\n",
    "    \n",
    "    delta_steering = dx/(rows/2) * 360/(2*np.pi*25.0) / 6.0     \n",
    "    steering += delta_steering\n",
    "    \n",
    "    return image, steering\n",
    "\n",
    "\n",
    "def random_brightness(image):\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    alpha = np.random.uniform(low=.2, high=.9, size=None)\n",
    "    hsv[:,:,2] = (hsv[:,:,2] * alpha).astype('uint8')\n",
    "    rgb = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "    \n",
    "    return rgb\n",
    "\n",
    "\n",
    "def random_flip(image,steering):\n",
    "    coin=np.random.randint(0, 2)\n",
    "    if coin == 0:\n",
    "        image = cv2.flip(image,1)\n",
    "        steering = -steering\n",
    "    \n",
    "    return image, steering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_and_steering(idx, cam_choice, left_im_, center_im_, right_im_, steer):\n",
    "    \"\"\"\n",
    "    idx: index of image\n",
    "    cam_choice: center_im / left_im / right_im\n",
    "    \"\"\"\n",
    "    assert cam_choice in 'LCR'\n",
    "    offset = 1.2 \n",
    "    dist = 100.0\n",
    "    \n",
    "    cam = {'C':center_im_, 'L':left_im_, 'R':right_im_}[cam_choice]\n",
    "    image = cv2.imread(DATA_PATH + cam[idx].strip()) #beware of leading whitespaces!\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    if cam_choice == 'C':\n",
    "        delta_steering = 0\n",
    "    elif cam_choice == 'L':\n",
    "        delta_steering = -offset/dist * 360/(2*np.pi)/25.0        \n",
    "    elif cam_choice == 'R':\n",
    "        delta_steering = offset/dist * 360/(2*np.pi)/25.0 \n",
    "\n",
    "    steering = steer[idx] + delta_steering\n",
    "    \n",
    "    return image, steering\n",
    "\n",
    "#try\n",
    "cam_choice = random.choice('LCR')   \n",
    "image, steering = read_image_and_steering(10, cam_choice, left_im, center_im, right_im, steering_rad)\n",
    "\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steering angle prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dat[['left','center','right']].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creation of the training & validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = training_dat[['left','center','right']]\n",
    "Y_train = training_dat['steering']\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we convert the input data into Numpy arrays\n",
    "X_left  = X_train['left'].as_matrix()\n",
    "X_right = X_train['right'].as_matrix()\n",
    "X_train = X_train['center'].as_matrix()\n",
    "\n",
    "Y_train = Y_train.as_matrix().astype(np.float32) #we don't need float64\n",
    "\n",
    "#for validation, we only keep the center image\n",
    "X_val = X_val['center'].as_matrix()\n",
    "\n",
    "Y_val = Y_val.as_matrix().astype(np.float32) #we don't need float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%xdel training_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_train[:5]:\\n',X_train[:5])\n",
    "print()\n",
    "print('Y_train[:5]:\\n',Y_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_example(left_im_, center_im_, right_im_, steer, drop_small_angle_prob = 0.95, verbose=False):\n",
    "    \"\"\"\n",
    "    drop_small_angle_prob =  2 : we drop all examples with a 0 angle\n",
    "    drop_small_angle_prob = -1 : we keep all examples with a 0 angle\n",
    "    \"\"\"\n",
    "    \n",
    "    ONE_DEGREE_THRESHOLD = 0.0175 #one degree in radian\n",
    "    while True:\n",
    "        idx = np.random.randint(0, len(steer))\n",
    "        if np.absolute(steer[idx]) > ONE_DEGREE_THRESHOLD or \\\n",
    "            np.random.uniform(0,1) > drop_small_angle_prob: #we keep only very few training examples with a ~0 steering angle\n",
    "            break\n",
    "    \n",
    "    \n",
    "    if verbose:\n",
    "        print('training example at index: {}'.format(idx))\n",
    "    \n",
    "    lcr = random.choice('LCR')\n",
    "    if verbose:    \n",
    "        print('L/C/R: {}'.format(lcr))\n",
    "    \n",
    "    image, steering = read_image_and_steering(idx, lcr, left_im_, center_im_, right_im_, steer)\n",
    "    if verbose:\n",
    "        print('steering: {}'.format(steering))\n",
    "        plt.imshow(image)\n",
    "        \n",
    "    image, steering = random_shear(image, steering, shear_range=40)\n",
    "    if verbose:\n",
    "        print('steering: {}'.format(steering))\n",
    "        plt.figure()\n",
    "        plt.imshow(image)    \n",
    "    \n",
    "    image, steering = random_crop(image, steering)\n",
    "    if verbose:\n",
    "        print('steering: {}'.format(steering))\n",
    "        plt.figure()\n",
    "        plt.imshow(image)\n",
    "    \n",
    "    image, steering = random_flip(image,steering)\n",
    "    if verbose:\n",
    "        print('steering: {}'.format(steering))\n",
    "        plt.figure()\n",
    "        plt.imshow(image)\n",
    "    \n",
    "    image = random_brightness(image)\n",
    "    if verbose:\n",
    "        plt.figure()\n",
    "        plt.imshow(image)\n",
    "    \n",
    "    return image.astype('uint8'), steering.astype('float32')\n",
    "    \n",
    "\n",
    "image, steering = generate_training_example(X_train, X_left, X_right, Y_train, verbose=True)\n",
    "plt.imshow(image)    \n",
    "print('steering: {}'.format(steering))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def generate_training_example_OLD(left_im_, center_im_, right_im_, steer, verbose=False):\n",
    "    \n",
    "    idx = np.random.randint(0, len(steer))\n",
    "    if verbose:\n",
    "        print('training example at index: {}'.format(idx))\n",
    "    \n",
    "    lcr = random.choice('LCR')\n",
    "    if verbose:    \n",
    "        print('L/C/R: {}'.format(lcr))\n",
    "    \n",
    "    image, steering = read_image_and_steering(idx, lcr, left_im_, center_im_, right_im_, steer)\n",
    "    if verbose:\n",
    "        print('steering: {}'.format(steering))\n",
    "        plt.imshow(image)\n",
    "        \n",
    "    image, steering = random_shear(image, steering, shear_range=40)\n",
    "    if verbose:\n",
    "        print('steering: {}'.format(steering))\n",
    "        plt.figure()\n",
    "        plt.imshow(image)    \n",
    "    \n",
    "    image, steering = random_crop(image, steering)\n",
    "    if verbose:\n",
    "        print('steering: {}'.format(steering))\n",
    "        plt.figure()\n",
    "        plt.imshow(image)\n",
    "    \n",
    "    image, steering = random_flip(image,steering)\n",
    "    if verbose:\n",
    "        print('steering: {}'.format(steering))\n",
    "        plt.figure()\n",
    "        plt.imshow(image)\n",
    "    \n",
    "    image = random_brightness(image)\n",
    "    if verbose:\n",
    "        plt.figure()\n",
    "        plt.imshow(image)\n",
    "    \n",
    "    return image.astype('uint8'), steering.astype('float32')\n",
    "    \n",
    "\n",
    "image, steering = generate_training_example(X_train, X_left, X_right, Y_train, verbose=True)\n",
    "plt.imshow(image)    \n",
    "print('steering: {}'.format(steering))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_validation_set(X_val, Y_val):\n",
    "    \n",
    "    images = np.empty((len(X_val), CROPPED_DIM, CROPPED_DIM,3), dtype='uint8')\n",
    "    steerings = np.empty(len(X_val), dtype='float32')\n",
    "    for i in range(len(X_val)):\n",
    "        #quick hack: we put 'None' as the left and right cam images for the validation set,\n",
    "        #and we always chose 'C' for the center camera.\n",
    "        image, steering = read_image_and_steering(i, 'C', None, X_val, None, Y_val)\n",
    "        \n",
    "        #hack: we do not crop images for the validation set: all cropping params are set to 0.\n",
    "        #TODO : set 'rand=False' param\n",
    "        images[i], steerings[i] = random_crop(image, steering, tx_min=0, tx_max=0, ty_min=0, ty_max=0)\n",
    "    \n",
    "    return images, steerings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_batch(left_im_, center_im_, right_im_, steer, batch_size = 32):\n",
    "    \n",
    "    batch_images = np.empty((batch_size, CROPPED_DIM, CROPPED_DIM, 3), dtype='uint8')\n",
    "    batch_steerings = np.empty(batch_size, dtype='float32')\n",
    "    while True:\n",
    "        for i in range(batch_size):\n",
    "            image, steering = generate_training_example(left_im_, center_im_, right_im_, steer)\n",
    "            batch_images[i] = image\n",
    "            batch_steerings[i] = steering\n",
    "            \n",
    "        yield batch_images, batch_steerings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: x/127.5 - 1.0,input_shape=(CROPPED_DIM,CROPPED_DIM,3)))\n",
    "model.add(Convolution2D(32, 8,8 ,border_mode='same', subsample=(4,4)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, 8,8 ,border_mode='same',subsample=(4,4)))\n",
    "model.add(Activation('relu',name='relu2'))\n",
    "model.add(Convolution2D(128, 4,4,border_mode='same',subsample=(2,2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(128, 2,2,border_mode='same',subsample=(1,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "old syntax:\n",
    "history = model.fit_generator(train_generator,\n",
    "                    samples_per_epoch=20000, nb_epoch=nb_epoch,\n",
    "                    validation_data=(X_val,Y_val),verbose=1)\n",
    "\n",
    "new syntax:\n",
    "history = model.fit_generator(train_generator,\n",
    "                    steps_per_epoch = 20000 // BATCH_SIZE,          \n",
    "                    epochs = NB_EPOCH,\n",
    "                    verbose = 1,\n",
    "                    use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "\n",
    "train_generator = generate_training_batch(X_left, X_train, X_right, Y_train, BATCH_SIZE)\n",
    "\n",
    "X_val, Y_val = get_validation_set(X_val,Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_train data type:', X_train.dtype)\n",
    "print('Y_train data type:', Y_train.dtype)\n",
    "print('X_val data type:', X_val.dtype)\n",
    "print('Y_val data type:', Y_val.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's launch the training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n1\n",
    "\n",
    "adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(optimizer=adam, loss='mse')\n",
    "\n",
    "NB_EPOCH = 10\n",
    "\n",
    "history_object = model.fit_generator(train_generator,\n",
    "                    samples_per_epoch= 20, #20000, #len(Y_train),\n",
    "                    nb_epoch=NB_EPOCH,\n",
    "                    validation_data=(X_val,Y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_seb4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### print the keys contained in the history object\n",
    "print(history_object.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_object.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python drive1.py model_seb2.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
